{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "851a7788e8214942863cbd4099064ab2",
        "deepnote_cell_type": "markdown",
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Nicolas Herrera\n",
        "- Nombre de alumno 2: Lucas Carrasco\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f23a189afdec4e198683308db70e43b7",
        "deepnote_cell_type": "markdown",
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/vspartamo/MDS7202)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
        "deepnote_cell_type": "markdown",
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà [10 Puntos]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
        "deepnote_cell_type": "markdown",
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/57133330/188281408-c67df9ee-fd1f-4b37-833b-f02848f1ce02.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000 #Este par√°metro si lo pueden modificar\n",
        "\n",
        "def create_data(n_samples):\n",
        "\n",
        "    # Lunas\n",
        "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "    # Blobs\n",
        "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "    # Datos desiguales\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "    # Generamos Dataset\n",
        "    dataset = {\n",
        "        'moons':{\n",
        "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "        },\n",
        "        'blobs':{\n",
        "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "        },\n",
        "        'mutated':{\n",
        "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "        }\n",
        "    }\n",
        "    return dataset\n",
        "\n",
        "data_sets = create_data(n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "cell_id": "643d6b35af5541358f481fda4d3fc51f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 267,
        "execution_start": 1714108733824,
        "id": "CO3JFqezrqC3",
        "outputId": "61a8cca1-3460-44dc-c23f-7dffb853b9a6",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def plot_scatter(x, y, marker):\n",
        "    fig = go.Scatter(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        mode='markers',\n",
        "        marker=marker,\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def scale_data(data):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    return data_scaled\n",
        "\n",
        "def plot_clusters(data_sets):\n",
        "    labels = {}\n",
        "    times = {}\n",
        "    silhouette = {}\n",
        "\n",
        "    algorithms = [KMeans, DBSCAN, AgglomerativeClustering, GaussianMixture]\n",
        "\n",
        "    for key in data_sets:\n",
        "        \n",
        "        # Escalamos los datos\n",
        "        data_sets[key]['x_scaled'] = scale_data(data_sets[key]['x'])\n",
        "        \n",
        "        labels[key] = {}\n",
        "        times[key] = {}\n",
        "        silhouette[key] = {}\n",
        "        \n",
        "        for algorithm in algorithms:\n",
        "            algorithm_to_use = None\n",
        "            \n",
        "            if algorithm is DBSCAN:\n",
        "                algorithm_to_use = algorithm(eps=0.03)\n",
        "            elif algorithm is GaussianMixture:\n",
        "                algorithm_to_use = algorithm(n_components=data_sets[key]['n_cluster'])\n",
        "            elif algorithm is AgglomerativeClustering:\n",
        "                algorithm_to_use = algorithm(n_clusters=data_sets[key]['n_cluster'], linkage='ward')\n",
        "            else:\n",
        "                algorithm_to_use = algorithm(n_clusters=data_sets[key]['n_cluster'])\n",
        "                \n",
        "            algorithm_name = str(algorithm.__name__)\n",
        "            start = time.time()\n",
        "            labels[key][algorithm_name] = algorithm_to_use.fit_predict(data_sets[key]['x_scaled'])\n",
        "            times[key][algorithm_name] = time.time() - start\n",
        "            try:\n",
        "                silhouette[key][algorithm_name] = silhouette_score(data_sets[key]['x_scaled'], labels[key][algorithm_name])\n",
        "            except:\n",
        "                silhouette[key][algorithm_name] = 0\n",
        "\n",
        "    subfig = make_subplots(\n",
        "        rows=3,\n",
        "        cols=4,\n",
        "        subplot_titles=(\n",
        "            f'{times[\"moons\"][\"KMeans\"]:.2f}s | Silhouette: {silhouette[\"moons\"][\"KMeans\"]:.2f}',\n",
        "            f'{times[\"moons\"][\"DBSCAN\"]:.2f}s | Silhouette: {silhouette[\"moons\"][\"DBSCAN\"]:.2f}',\n",
        "            f'{times[\"moons\"][\"AgglomerativeClustering\"]:.2f}s | Silhouette: {silhouette[\"moons\"][\"AgglomerativeClustering\"]:.2f}',\n",
        "            f'{times[\"moons\"][\"GaussianMixture\"]:.2f}s | Silhouette: {silhouette[\"moons\"][\"GaussianMixture\"]:.2f}',\n",
        "            f'{times[\"blobs\"][\"KMeans\"]:.2f}s | Silhouette: {silhouette[\"blobs\"][\"KMeans\"]:.2f}',\n",
        "            f'{times[\"blobs\"][\"DBSCAN\"]:.2f}s | Silhouette: {silhouette[\"blobs\"][\"DBSCAN\"]:.2f}',\n",
        "            f'{times[\"blobs\"][\"AgglomerativeClustering\"]:.2f}s | Silhouette: {silhouette[\"blobs\"][\"AgglomerativeClustering\"]:.2f}',\n",
        "            f'{times[\"blobs\"][\"GaussianMixture\"]:.2f}s | Silhouette: {silhouette[\"blobs\"][\"GaussianMixture\"]:.2f}',\n",
        "            f'{times[\"mutated\"][\"KMeans\"]:.2f}s | Silhouette: {silhouette[\"mutated\"][\"KMeans\"]:.2f}',\n",
        "            f'{times[\"mutated\"][\"DBSCAN\"]:.2f}s | Silhouette: {silhouette[\"mutated\"][\"DBSCAN\"]:.2f}',\n",
        "            f'{times[\"mutated\"][\"AgglomerativeClustering\"]:.2f}s | Silhouette: {silhouette[\"mutated\"][\"AgglomerativeClustering\"]:.2f}',\n",
        "            f'{times[\"mutated\"][\"GaussianMixture\"]:.2f}s | Silhouette: {silhouette[\"mutated\"][\"GaussianMixture\"]:.2f}'\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    for i, key in enumerate(data_sets):\n",
        "        for j, method in enumerate(labels[key]):\n",
        "            subfig.add_trace(\n",
        "                plot_scatter(\n",
        "                    data_sets[key]['x'][:, 0],\n",
        "                    data_sets[key]['x'][:, 1],\n",
        "                    dict(color=labels[key][method]),\n",
        "                ),\n",
        "                row=i+1,\n",
        "                col=j+1,\n",
        "            )\n",
        "\n",
        "    subfig.update_layout(height=900, width=1000, title_text=\"Clusters\", showlegend=False, title_font_size=1)\n",
        "    subfig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_samples = 1000\n",
        "data_sets = create_data(n_samples)\n",
        "plot_clusters(data_sets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_samples = 5000\n",
        "data_sets = create_data(n_samples)\n",
        "plot_clusters(data_sets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_samples = 10000\n",
        "data_sets = create_data(n_samples)\n",
        "plot_clusters(data_sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**An√°lisis**\n",
        "\n",
        "Lo primero a destacar es que DBSCAN cambia bastante sus resultados en el tercer dataset al aumentar la cantidad de datos. Esto se debe a c√≥mo funcinoa el algoritmo de DBSCAN, y a que el dataset posee 2 clusters bastante cercanos, por lo que al aumentar la cantidad de datos, los puntos m√°s cercanos de cada uno de estos clusters aumentan, y por lo tanto, el algoritmo los considera como un solo cluster. \n",
        "\n",
        "En general, para el primer dataset DBSCAN es por lejos el que mejor funciona, aunque tiene un coeficiente de silhouette un poco bajo para la buena estructura que se observa. Para el segundo set de datos KNN, Agglomerative y GMM se portan bien y tienen buenos coeficientes de silhouette, aunque cabe destacar que DBSCAN tambi√©n se porta bien para los casos con 1000 y 5000 datos, despu√©s de eso ya que empieza a equivocar y su coeficiente de silhouette baja. Finalmente para el tercero GMM es con diferencia el mejorm ya que los otros mezclan bastante, y toman partes de unos y de otros.\n",
        "\n",
        "Sobre cu√°nto demor√≥ cada algoritmo, en general KNN y GMM son los m√°s r√°pidos, y se mantienen con buenos tiempos aunque el dataset crezca. Luego, se encuentra DBSCAN, donde su tiempo parece crecer linealmente con la cantidad de datos (con 1000 se demor√≥ ~0.01, con 5000 ~0.05 y con 10000 ~0.1). Y finalmente se tiene Agglomerative, que es el m√°s lento de todos, y su tiempo crece exponencialmente con la cantidad de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd6e991646b44f50a4b13f01d1542415",
        "deepnote_cell_type": "markdown",
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**\n",
        "\n",
        "1. Usar atributos categ√≥ricos puede causar problemas en el c√°lculo de distancias, ya que se perder√≠a su significado. Esto podr√≠a llevar an√°lisis e interpretaciones incorrectas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzHTZ17xveU_"
      },
      "outputs": [],
      "source": [
        "# Carga de datos\n",
        "df = pd.read_parquet('aerolineas_lucer.parquet')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variables num√©ricas\n",
        "df_num = df.select_dtypes(include=np.number).drop(columns=['id'])\n",
        "df_num.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **An√°lisis**\n",
        "\n",
        "- **Age**: Distribuci√≥n bi-modal, con una concentraci√≥n en 25 y 39 a√±os. Al llegar a los 70 a√±os, y a los 60 a√±os, la cantidad de personas disminuye dr√°sticamente, mientras que a los 20 y a los 22 a√±os hay incrementos significativos. Las edades m√°s comunes llegan hasta los 6000 pasajeros, mientras que el promedio parece estar alrededor de los 3200.\n",
        "- **Flight distance**: hay una buena alta concentraci√≥n de vuelos que van entre 60 y 1100 km. Luego de los 1100 disminuye y se mantiene relativamente constante hasta los 4000 km, donde disminuye dr√°sticamente.\n",
        "- **Inflight wifi service**, **ease of online booking**, : son distribuciones bastante normales, donde, con notas entre 0 y 5, las notas se concentran entre el 2 y el 3. Cabe destacar que hay una cantidad mayor de 5 que de 0 en ambos casos.\n",
        "- **Departure/Arrival time convenient**, **Gate location**, **Food and drink**, **Online boarding, Seat comfort**, **Inflight entertainment**, **On-board service**, **Leg room service**, **Baggage handling**, **Check-in service**, **Inflight service**, **Cleanliness**: todas estas variables tienen una distribuci√≥n parecida. Distribuciones parecidas a normales, pero cargas hacia las notas m√°s altas, donde en general la moda est√° entre 3 y 4. En la mayor√≠a de estos casos las notas 0 son muy pocas.\n",
        "- **Departure Delay in Minutes**, **Arrival Delay in Minutes**: ambas variables tienen una distribuci√≥n muy parecidia, donde la mayor√≠a de los vuelos tienen retraso 0 (no tienen), y luego hay una distribuci√≥n exponencial decreciente donde sobre los 100 minutos de retraso hay muy pocos vuelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df_num.columns:\n",
        "    fig = px.histogram(df_num, x=col, title=col, width=1000, height=400)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Los datos **si ser√°n escalados** ya que hay variables con valores muy diferentes, como la distancia de vuelo, que puede llegar hasta los 4000, mientras que la mayor√≠a de las variables est√°n entre 0 y 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_num_scaled = scaler.fit_transform(df_num)\n",
        "df_num_scaled = pd.DataFrame(df_num_scaled, columns=df_num.columns)\n",
        "df_num_scaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation = df_num_scaled.corr()\n",
        "px.imshow(correlation, width=1000, height=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_num.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. **Justificaci√≥n:**\n",
        "\n",
        "La estrategia para escoger las variables consisti√≥ en seleccionar aquellas que presentaban una correlaci√≥n alta con m√°s variables. De esa manera, con pocas variables, se podr√≠a capturar m√°s informaci√≥n. Cabe destacar que la idea era intentar que cada una represente varias variables, pero siempre variables diferentes, as√≠ todas las variables se encuentran representadas. En los 3 primeros casos se observa bien eso, y en el √∫ltimo caso se seleccion√≥ una variable que, no representaba muy bien otras variables, pero era la que mejor lo hac√≠a para las variables restantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_num_reduced = df_num_scaled[['Inflight entertainment', 'Inflight service', 'Ease of Online booking', 'Online boarding']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
        "deepnote_cell_type": "markdown",
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/1e/a8/0e/1ea80e7cea0d429146580c7e91c5b944.gif\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ad1e70818ad748638ca0927b07a76125",
        "deepnote_cell_type": "code",
        "id": "gBYG238wrqC-"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# Creamos un transformador que solo deje las columnas que queremos\n",
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.columns]\n",
        "\n",
        "\n",
        "pca_pipeline = Pipeline([\n",
        "    ('selector', ColumnSelector(columns=['Inflight entertainment', 'Inflight service', 'Ease of Online booking', 'Online boarding'])),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('pca', PCA(n_components=2))\n",
        "])\n",
        "\n",
        "df_pca = pca_pipeline.fit_transform(df_num)\n",
        "df_pca = pd.DataFrame(df_pca, columns=['PCA1', 'PCA2'])\n",
        "df_pca.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.scatter(\n",
        "    df_pca, \n",
        "    x='PCA1', \n",
        "    y='PCA2', \n",
        "    width=1000, \n",
        "    height=600,\n",
        "    title='PCA'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observaciones:**\n",
        "\n",
        "Se observa que los puntos forman un espacio rectangular rotado que parece dividirse en lineas diagonales de puntos (algo as√≠ como lineas que van periodicamente saltandose partes), y en el centro hay una alta densidad de puntos. De esta forma la estructura obtenida usando PCA parece poseer estas lineas saltadas, con algo c√≥mo una gaussiana 2D en el centro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
        "deepnote_cell_type": "markdown",
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "be86896911244aa89e3b5f3f00a286af",
        "deepnote_cell_type": "code",
        "id": "iaPZFmjyrqDA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "pipeline_isolation_forest = Pipeline([\n",
        "    ('isolation_forest', IsolationForest(contamination=0.01)),\n",
        "])\n",
        "\n",
        "outliers = pipeline_isolation_forest.fit_predict(df_num)\n",
        "px.scatter(\n",
        "    df_pca, \n",
        "    x='PCA1', \n",
        "    y='PCA2', \n",
        "    color=outliers, \n",
        "    width=1000, \n",
        "    height=600, \n",
        "    title='Outliers', \n",
        "    color_continuous_scale=px.colors.sequential.Bluered\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**An√°lisis de resultados:**\n",
        "\n",
        "Los resultados no son muy prometedores, al menos en esta visualizaci√≥n los puntos parecen repartirse sobre todo el espacio sin un ordden aparente. De ninguna manera parece haber clusters claros, y por lo tanto no parece haber una buena detecci√≥n de anomal√≠as."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_clusters_range = range(3, 9)\n",
        "aic_scores = []\n",
        "bic_scores = []\n",
        "\n",
        "for n in n_clusters_range:\n",
        "    gmm = GaussianMixture(n_components=n, random_state=42)\n",
        "    gmm.fit(df_num)\n",
        "    aic = gmm.aic(df_num)\n",
        "    bic = gmm.bic(df_num)\n",
        "    aic_scores.append(aic)\n",
        "    bic_scores.append(bic) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=list(n_clusters_range), y=aic_scores, mode='lines+markers', name='AIC'))\n",
        "fig.add_trace(go.Scatter(x=list(n_clusters_range), y=bic_scores, mode='lines+markers', name='BIC'))\n",
        "fig.update_layout(title='AIC/BIC Scores', xaxis_title='Number of clusters', yaxis_title='Score')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cabe notar que para distintas semillas cambian los resultados, por lo que fij√°ndola con un valor igual a 42, se tiene que el valor donde se alcanza el m√≠nimo es AIC y BIC es 8, por lo que escogemos este n√∫mero de clusters se minimiza la complejidad manteniendo un buen ajuste tanto como en la curva AIC y la curva BIC, que coinciden en este n√∫mero de clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "pipeline_gmm = Pipeline([\n",
        "    ('selector', ColumnSelector(columns=['Inflight entertainment', 'Inflight service', 'Ease of Online booking', 'Online boarding'])),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('gmm', GaussianMixture(n_components=8, random_state=42))\n",
        "])\n",
        "\n",
        "labels = pipeline_gmm.fit_predict(df_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dd342e336254418ba766b29dce16b267",
        "deepnote_cell_type": "markdown",
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
        "deepnote_cell_type": "markdown",
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/7wTk.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuestas:**\n",
        "\n",
        "2. No es posible distinguir separaciones claras de los clusters en el gr√°fico de dos dimensiones, ya que estos se superponen mucho, y est√°n todos cruzados con otros. No parece haber una estructura clara en los datos.\n",
        "\n",
        "3. Los clusters 2, 3 y 5 parecen corresponder a personas con treintaitantos, y con viajes de alrededord de 1300 km que en general ponen notas que pueden varias entre 2-3. Los clusters 0 y 4 parecen corresponder a personas tambi√©n con treintaitantos pero que realizan vuelos m√°s cortos, vuelos de ~800 km, y con notas un poco m√°s altas que en el otro grupo, en el rango 2-4. Finalmente el cluster 1 parece corresponder a personas con 4X a√±os que realizan vuelos de ~1300 km, y que ponen notas alrededor de ~3.\n",
        "\n",
        "\n",
        "5. Luego de visualizar en 3D los clusters se observan divisiones un poco m√°s marcadas entre algunos clusters, en particular se observa que los clusters son laminas que pasan entre los otros, pero que forman capas dentro del espacio. Esto no cambia mucho las conclusiones anteriores, ya que los clusters siguen atravesandose entre s√≠, y no hay una estructura clara en los datos. Sin embargo, hay ciertos insights que se pueden obtener, como que las personas del cluster 4 y del 5 quedan muy separadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
        "deepnote_cell_type": "code",
        "id": "XmZrz15GrqDC"
      },
      "outputs": [],
      "source": [
        "projected_centers = pca_pipeline['pca'].transform(pipeline_gmm.named_steps['gmm'].means_)\n",
        "\n",
        "px.scatter(\n",
        "    df_pca, \n",
        "    x='PCA1', \n",
        "    y='PCA2', \n",
        "    color=labels, \n",
        "    width=1000, \n",
        "    height=600, \n",
        "    title='Clusters', \n",
        "    color_continuous_scale=px.colors.sequential.Viridis,\n",
        "    labels={'color': 'Cluster'}\n",
        ").add_trace(\n",
        "    go.Scatter(\n",
        "        x=projected_centers[:, 0],\n",
        "        y=projected_centers[:, 1],\n",
        "        mode='markers',\n",
        "        marker=dict(size=10, color='red'),\n",
        "        name='Centers'\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import show of dataframes\n",
        "from IPython.display import display\n",
        "\n",
        "df_num_clustered = df_num.copy()\n",
        "df_num_clustered['cluster'] = labels\n",
        "\n",
        "for value in df_num_clustered['cluster'].unique():\n",
        "    cluster = df_num_clustered[df_num_clustered['cluster'] == value]\n",
        "    print(f'Cluster {value}')\n",
        "    display(pd.DataFrame(cluster.describe()))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pca con 3 componentes\n",
        "pca_pipeline_3 = Pipeline([\n",
        "    ('selector', ColumnSelector(columns=['Inflight entertainment', 'Inflight service', 'Ease of Online booking', 'Online boarding'])),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('pca', PCA(n_components=3))\n",
        "])\n",
        "\n",
        "df_pca_3 = pca_pipeline_3.fit_transform(df_num)\n",
        "df_pca_3 = pd.DataFrame(df_pca_3, columns=['PCA1', 'PCA2', 'PCA3'])\n",
        "\n",
        "# plot 3D\n",
        "fig = px.scatter_3d(\n",
        "    df_pca_3, \n",
        "    x='PCA1', \n",
        "    y='PCA2', \n",
        "    z='PCA3', \n",
        "    color=labels, \n",
        "    width=1000, \n",
        "    height=600, \n",
        "    title='Clusters', \n",
        "    color_continuous_scale=px.colors.sequential.Viridis,\n",
        "    labels={'color': 'Cluster'}\n",
        ")\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "nb-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
