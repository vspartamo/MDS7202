{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyPTffTLug7i"
   },
   "source": [
    "# **Laboratorio 11: LLM y Agentes Aut√≥nomos ü§ñ**\n",
    "\n",
    "MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pbWVyntzbvL"
   },
   "source": [
    "### **Cuerpo Docente:**\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6ikgVYzghB"
   },
   "source": [
    "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados**\n",
    "\n",
    "- Nombre de alumno 1: Nicolas Herrera\n",
    "- Nombre de alumno 2: Lucas Carrasco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMJ-owchzjFf"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/vspartamo/MDS7202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUuwsXrKzmkK"
   },
   "source": [
    "## **Temas a tratar**\n",
    "\n",
    "- Reinforcement Learning\n",
    "- Large Language Models\n",
    "\n",
    "## **Reglas:**\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### **Objetivos principales del laboratorio**\n",
    "\n",
    "- Resoluci√≥n de problemas secuenciales usando Reinforcement Learning\n",
    "- Habilitar un Chatbot para entregar respuestas √∫tiles usando Large Language Models.\n",
    "\n",
    "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hmHHQ9BuyAG"
   },
   "source": [
    "## **1. Reinforcement Learning (2.0 puntos)**\n",
    "\n",
    "En esta secci√≥n van a usar m√©todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gOcejYb6uzOO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install -qqq gymnasium stable_baselines3\n",
    "!pip install -qqq swig\n",
    "!pip install -qqq gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBPet_Mq8dX9"
   },
   "source": [
    "### **1.1 Blackjack (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "La idea de esta subsecci√≥n es que puedan implementar m√©todos de RL y as√≠ generar una estrategia para jugar el cl√°sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
    "\n",
    "Comencemos primero preparando el ambiente. El siguiente bloque de c√≥digo transforma las observaciones del ambiente a `np.array`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LpZ8bBKk9ZlU"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import MultiDiscrete\n",
    "import numpy as np\n",
    "\n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(FlattenObservation, self).__init__(env)\n",
    "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.array(observation).flatten()\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "env = FlattenObservation(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ6J1_-Y9nHO"
   },
   "source": [
    "#### **1.1.1 Descripci√≥n de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripci√≥n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5i1Wt1p770x"
   },
   "source": [
    "`escriba su respuesta ac√°`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmcX6bRC9agQ"
   },
   "source": [
    "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci√≥n 5000 veces y reporte el promedio y desviaci√≥n de las recompensas. ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica? ¬øC√≥mo podr√≠a interpretar las recompensas obtenidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p2PrLLR9yju"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEO_dY4x_SJu"
   },
   "source": [
    "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9JsFA1wGmnH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-bpdb8wZID1"
   },
   "source": [
    "#### **1.1.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. ¬øC√≥mo es el performance de su agente? ¬øEs mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-d7d8GFf7F6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO-EsAaPAYEm"
   },
   "source": [
    "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
    "\n",
    "Genere una funci√≥n que reciba un estado y retorne la accion del agente. Luego, use esta funci√≥n para entregar la acci√≥n escogida frente a los siguientes escenarios:\n",
    "\n",
    "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
    "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
    "\n",
    "¬øSon coherentes sus acciones con las reglas del juego?\n",
    "\n",
    "Hint: ¬øA que clase de python pertenecen los estados? Pruebe a usar el m√©todo `.reset` para saberlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh8XlGyzwtRp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEqCTqqroh03"
   },
   "source": [
    "### **1.2 LunarLander**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la secci√≥n 2.1, en esta secci√≥n usted se encargar√° de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
    "\n",
    "Comencemos preparando el ambiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nvQUyuZ_FtZ4"
   },
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Box2D is not installed, run `pip install gymnasium[box2d]`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gymnasium\\envs\\box2d\\bipedal_walker.py:15\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mBox2D\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m         circleShape,\n\u001b[0;32m     18\u001b[0m         contactListener,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         revoluteJointDef,\n\u001b[0;32m     23\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Box2D'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLunarLander-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuous\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# notar el par√°metro continuous = True\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gymnasium\\envs\\registration.py:756\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    753\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m env_spec\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m \u001b[43mload_env_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;66;03m# Determine if to use the rendering\u001b[39;00m\n\u001b[0;32m    759\u001b[0m render_modes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gymnasium\\envs\\registration.py:545\u001b[0m, in \u001b[0;36mload_env_creator\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \n\u001b[0;32m    538\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    The environment constructor for the given environment name.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 545\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:994\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gymnasium\\envs\\box2d\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbipedal_walker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BipedalWalker, BipedalWalkerHardcore\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcar_racing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CarRacing\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlunar_lander\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LunarLander, LunarLanderContinuous\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gymnasium\\envs\\box2d\\bipedal_walker.py:25\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m         circleShape,\n\u001b[0;32m     18\u001b[0m         contactListener,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         revoluteJointDef,\n\u001b[0;32m     23\u001b[0m     )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBox2D is not installed, run `pip install gymnasium[box2d]`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: Box2D is not installed, run `pip install gymnasium[box2d]`"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par√°metro continuous = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBU4lGX3wpN6"
   },
   "source": [
    "Noten que se especifica el par√°metro `continuous = True`. ¬øQue implicancias tiene esto sobre el ambiente?\n",
    "\n",
    "Adem√°s, se le facilita la funci√≥n `export_gif` para el ejercicio 2.2.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRiWpSo9yfr9"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "def export_gif(model, n = 5):\n",
    "  '''\n",
    "  funci√≥n que exporta a gif el comportamiento del agente en n episodios\n",
    "  '''\n",
    "  images = []\n",
    "  for episode in range(n):\n",
    "    obs = model.env.reset()\n",
    "    img = model.env.render()\n",
    "    done = False\n",
    "    while not done:\n",
    "      images.append(img)\n",
    "      action, _ = model.predict(obs)\n",
    "      obs, reward, done, info = model.env.step(action)\n",
    "      img = model.env.render(mode=\"rgb_array\")\n",
    "\n",
    "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk5VJVppXh3N"
   },
   "source": [
    "#### **1.2.1 Descripci√≥n de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripci√≥n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci√≥n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. ¬øComo se distinguen las acciones de este ambiente en comparaci√≥n a `Blackjack`?\n",
    "\n",
    "Nota: recuerde que se especific√≥ el par√°metro `continuous = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb-u9LUE8O9a"
   },
   "source": [
    "`escriba su respuesta ac√°`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YChodtNQwzG2"
   },
   "source": [
    "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci√≥n 10 veces y reporte el promedio y desviaci√≥n de las recompensas. ¬øC√≥mo calificar√≠a el performance de esta pol√≠tica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bwc3A0GX7a8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQrZVQflX_5f"
   },
   "source": [
    "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_6Ia9uoF7Hs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z-oIUSrlAsY"
   },
   "source": [
    "#### **1.2.4 Evaluaci√≥n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. ¬øC√≥mo es el performance de su agente? ¬øEs mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ophyU3KrWrwl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6Xw4YHT3P5d"
   },
   "source": [
    "#### **1.2.5 Optimizaci√≥n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par√°metros como:\n",
    "- `total_timesteps`\n",
    "- `learning_rate`\n",
    "- `batch_size`\n",
    "\n",
    "Una vez optimizado el modelo, use la funci√≥n `export_gif` para estudiar el comportamiento de su agente en la resoluci√≥n del ambiente y comente sobre sus resultados.\n",
    "\n",
    "Adjunte el gif generado en su entrega (mejor a√∫n si adem√°s adjuntan el gif en el markdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aItYF6sr6F_6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPUY-Ktgf2BO"
   },
   "source": [
    "## **2. Large Language Models (4.0 puntos)**\n",
    "\n",
    "En esta secci√≥n se enfocar√°n en habilitar un Chatbot que nos permita responder preguntas √∫tiles a trav√©s de LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4fPRRihGLe"
   },
   "source": [
    "### **2.0 Configuraci√≥n Inicial**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Como siempre, cargamos todas nuestras API KEY al entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ud2Xm_k-hFJn"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001981585DDC0>, default_metadata=())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj9JvQUsgZZJ"
   },
   "source": [
    "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsecci√≥n es que habiliten un chatbot que pueda responder preguntas usando informaci√≥n contenida en documentos PDF a trav√©s de **Retrieval Augmented Generation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxOQroVnaZ5"
   },
   "source": [
    "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
    "\n",
    "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
    "  - 2 documentos .pdf como m√≠nimo.\n",
    "  - 50 p√°ginas de contenido como m√≠nimo entre todos los documentos.\n",
    "  - Ideas para documentos: Documentos relacionados a temas acad√©micos, laborales o de ocio. Aprovechen este ejercicio para construir algo √∫til y/o relevante para ustedes!\n",
    "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
    "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
    "  - **Recuerden adjuntar los documentos en su entrega**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5D1tIRCi4oJJ",
    "outputId": "39f6d4fc-63cb-4b9b-d48f-48d60df25ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kzq2TjWCnu15"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "doc_paths = ['AttentionIsAllYouNeed.pdf', 'BERT.pdf', 'ChainOfThought.pdf'] # rellenar con los path a sus documentos\n",
    "\n",
    "assert len(doc_paths) >= 2, \"Deben adjuntar un m√≠nimo de 2 documentos\"\n",
    "\n",
    "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
    "assert total_paginas >= 50, f\"P√°ginas insuficientes: {total_paginas}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 0}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani‚àó\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer‚àó\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar‚àó\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit‚àó\\nGoogle Research\\nusz@google.com\\nLlion Jones‚àó\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez‚àó ‚Ä†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\n≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó ‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n‚àóEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n‚Ä†Work performed while at Google Brain.\\n‚Ä°Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 1}, page_content='1 Introduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht‚àí1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 2}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 3}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by ‚àödk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n‚àödk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1‚àödk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1‚àödk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q ¬∑ k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 4}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V) = Concat(head1, ...,headh)WO\\nwhere headi = Attention(QWQ\\ni , KWK\\ni , V WV\\ni )\\nWhere the projections are parameter matricesWQ\\ni ‚àà Rdmodel√ódk , WK\\ni ‚àà Rdmodel√ódk , WV\\ni ‚àà Rdmodel√ódv\\nand WO ‚àà Rhdv√ódmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n‚Ä¢ In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n‚Ä¢ The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n‚Ä¢ Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to ‚àí‚àû) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by ‚àödmodel.\\n5')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "docs = []\n",
    "for path in doc_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    docs += loader.load()\n",
    "    \n",
    "docs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r811-P71nizA"
   },
   "source": [
    "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
    "\n",
    "Vectorice los documentos y almacene sus representaciones de manera acorde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "n-yXAdCSn4JM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 0}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani‚àó\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer‚àó\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar‚àó\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit‚àó\\nGoogle Research\\nusz@google.com\\nLlion Jones‚àó\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez‚àó ‚Ä†\\nUniversity of Toronto\\naidan@cs.toronto.edu'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 0}, page_content='University of Toronto\\naidan@cs.toronto.edu\\n≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó ‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 0}, page_content='based solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 0}, page_content='our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n‚àóEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started'),\n",
       " Document(metadata={'source': 'AttentionIsAllYouNeed.pdf', 'page': 0}, page_content='the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "splits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x19816c93350>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUkP5zrnyBK"
   },
   "source": [
    "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
    "\n",
    "Habilite la soluci√≥n RAG a trav√©s de una *chain* y gu√°rdela en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gPIySdDFn99l"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever_chain = retriever | format_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycg5S5i_n-kL"
   },
   "source": [
    "#### **2.1.4 Verificaci√≥n de respuestas (0.5 puntos)**\n",
    "\n",
    "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluci√≥n para cada una. ¬øSu soluci√≥n RAG entrega las respuestas que esperaba?\n",
    "\n",
    "Ejemplo de tupla:\n",
    "- Pregunta: ¬øQui√©n es el presidente de Chile?\n",
    "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# noten como ahora existe el par√°metro de context!\n",
    "rag_template = '''\n",
    "Eres un asistente experto en investigaci√≥n sobre LLMs.\n",
    "Tu √∫nico rol es contestar preguntas del usuario a partir de informaci√≥n relevante que te sea proporcionada.\n",
    "Responde siempre de la forma m√°s completa posible y usando toda la informaci√≥n entregada.\n",
    "Responde s√≥lo lo que te pregunten a partir de la informaci√≥n relevante, NUNCA inventes una respuesta.\n",
    "\n",
    "Informaci√≥n relevante: {context}\n",
    "Pregunta: {question}\n",
    "Respuesta:\n",
    "'''\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever_chain,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    } # Los par√°metros de la plantilla\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "S_UiEn1hoZYR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta esperada:  Un Transformer es un tipo de arquitectura de red neuronal que usa un encoder-decoder para modelar relaciones en datos secuenciales.\n",
      "Respuesta obtenita:  Un Transformer es un modelo de transducci√≥n que utiliza √∫nicamente auto-atenci√≥n para calcular representaciones de su entrada y salida, sin usar RNNs alineados con la secuencia o convoluciones.  Su arquitectura se compone de un codificador y un decodificador, ambos formados por una pila de N=6 capas id√©nticas. Cada capa tiene dos subcapas: la primera es un mecanismo de auto-atenci√≥n multi-cabeza, y la segunda es una capa de alimentaci√≥n directa totalmente conectada.  Tanto el codificador como el decodificador utilizan codificaciones posicionales.  El modelo base utiliza una tasa de abandono (dropout) de Pdrop = 0.1 y durante el entrenamiento se emplea suavizado de etiquetas con un valor de œµls = 0.1.\n",
      "\n",
      "\n",
      "Respuesta esperada:  Se puede descomponer el problema en partes m√°s peque√±as y resolver cada parte por separado.\n",
      "Respuesta obtenita:  Seg√∫n la informaci√≥n proporcionada, la t√©cnica Chain of Thought (pensamiento en cadena) se puede usar para resolver problemas complejos con un LLM.  Esta t√©cnica permite descomponer problemas de m√∫ltiples pasos en subproblemas m√°s peque√±os y manejables,  imitando un proceso de pensamiento paso a paso para llegar a la respuesta.  Adem√°s,  los modelos de lenguaje pueden generar cadenas de pensamiento si se proporcionan demostraciones de razonamiento de pensamiento en cadena en los ejemplos para la indicaci√≥n de pocos disparos (few-shot prompting).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_answer_list = [\n",
    "    (\n",
    "        \"Qu√© es un Transformer?\",\n",
    "        \"Un Transformer es un tipo de arquitectura de red neuronal que usa un encoder-decoder para modelar relaciones en datos secuenciales.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Seg√∫n Chain of Thought, ¬øqu√© t√©cnica se puede usar para resolver un problema complejo con un LLM?\",\n",
    "        \"Se puede descomponer el problema en partes m√°s peque√±as y resolver cada parte por separado.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "for question_answer in question_answer_list:\n",
    "    res = rag_chain.invoke(question_answer[0])\n",
    "    print(\"Respuesta esperada: \", question_answer[1])\n",
    "    print(\"Respuesta obtenita: \", res)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA**: La soluci√≥n de RAG entrega respuestas correctas, y bastante parecidas a las esperadas. Al ser preguntas no simples, era dif√≠cil que la respuesta fuera exactamente igual, pero en general, la respuesta entregada por RAG es correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8d5zTMHoUgF"
   },
   "source": [
    "#### **2.1.5 Sensibilidad de Hiperpar√°metros (0.5 puntos)**\n",
    "\n",
    "Extienda el an√°lisis del punto 2.1.4 analizando c√≥mo cambian las respuestas entregadas cambiando los siguientes hiperpar√°metros:\n",
    "- `Tama√±o del chunk`. (*¬øC√≥mo repercute que los chunks sean mas grandes o chicos?*)\n",
    "- `La cantidad de chunks recuperados`. (*¬øQu√© pasa si se devuelven muchos/pocos chunks?*)\n",
    "- `El tipo de b√∫squeda`. (*¬øC√≥mo afecta el tipo de b√∫squeda a las respuestas de mi RAG?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UDh_QgeXLGHc"
   },
   "outputs": [],
   "source": [
    "def try_other_config(\n",
    "    chunk_size: int = 500, \n",
    "    ammount_of_chunks: int = 3, \n",
    "    search_type: str = 'similarity'\n",
    "):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
    "    vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=search_type, # m√©todo de b√∫squeda\n",
    "        search_kwargs={\"k\": ammount_of_chunks}, # n¬∞ documentos a recuperar\n",
    "    )\n",
    "\n",
    "    retriever_chain = retriever | format_docs\n",
    "\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever_chain,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    for question_answer in question_answer_list:\n",
    "        res = rag_chain.invoke(question_answer[0])\n",
    "        print(\"Respuesta esperada: \", question_answer[1])\n",
    "        print(\"Respuesta obtenita: \", res)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**PROBANDO CAMBIAR TAMA√ëO DE CHUNK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta esperada:  Un Transformer es un tipo de arquitectura de red neuronal que usa un encoder-decoder para modelar relaciones en datos secuenciales.\n",
      "Respuesta obtenita:  Basado en la informaci√≥n proporcionada, un Transformer es un modelo que puede ser usado para tareas de traducci√≥n.  Tambi√©n se menciona que existe una versi√≥n del Transformer referida como \"Transformer\".\n",
      "\n",
      "\n",
      "Respuesta esperada:  Se puede descomponer el problema en partes m√°s peque√±as y resolver cada parte por separado.\n",
      "Respuesta obtenita:  Seg√∫n la informaci√≥n proporcionada, la t√©cnica \"chain of thought\" es particularmente adecuada para resolver problemas complejos con un LLM.  El ejemplo dado muestra que un modelo que produce un \"chain of thought\" puede resolver un problema.  Sin embargo, la informaci√≥n no describe la t√©cnica en s√≠ misma, solo indica su idoneidad para este prop√≥sito.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_other_config(chunk_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA**: Al achicar el tama√±o de los chunks se obtienen respuestas especificas pero distintas a lo que buscabamos. La respuesta es incompleta y difiere de lo que se esperaba. Esto se debe a que al achicar el tama√±o de los chunks, se obtiene menos informaci√≥n y contexto para responder la pregunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta esperada:  Un Transformer es un tipo de arquitectura de red neuronal que usa un encoder-decoder para modelar relaciones en datos secuenciales.\n",
      "Respuesta obtenita:  Un Transformer es una nueva arquitectura de red simple basada √∫nicamente en mecanismos de atenci√≥n, que prescinde por completo de la recurrencia y las convoluciones.  Est√° compuesta por un codificador y un decodificador, ambos con pilas de capas de auto-atenci√≥n multi-cabeza y redes completamente conectadas punto a punto.  El modelo codificador tiene una pila de N=6 capas id√©nticas, cada una con dos subcapas: una de auto-atenci√≥n multi-cabeza y otra red de avance completamente conectada.  Se utiliza una conexi√≥n residual alrededor de cada subcapa, seguida de normalizaci√≥n por capas.  Se aplica abandono (dropout) a la salida de cada subcapa, antes de sumarla a la entrada de la subcapa y normalizarla.  Tambi√©n se aplica abandono a la suma de las incrustaciones y las codificaciones posicionales.\n",
      "\n",
      "\n",
      "Respuesta esperada:  Se puede descomponer el problema en partes m√°s peque√±as y resolver cada parte por separado.\n",
      "Respuesta obtenita:  Seg√∫n la informaci√≥n proporcionada, la t√©cnica para resolver un problema complejo con un LLM es el *Chain-of-Thought prompting*.  Este m√©todo consiste en proporcionar ejemplos de razonamiento paso a paso (cadenas de pensamiento) en los ejemplos utilizados para el *few-shot prompting*.  Esto permite que los modelos de lenguaje generen sus propias cadenas de pensamiento para resolver problemas, incluso aquellos que de otra manera ser√≠an incorrectos.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_other_config(chunk_size=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA**: Al aumentar el tama√±o de los chunks se obtiene informaci√≥n muchisimo m√°s completa. Al tener tanta informaci√≥n, y dejar que el LLM la procese, se obtiene una respuesta mucho m√°s completa y correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBANDO CAMBIAR CANTIDAD DE CHUNKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta esperada:  Un Transformer es un tipo de arquitectura de red neuronal que usa un encoder-decoder para modelar relaciones en datos secuenciales.\n",
      "Respuesta obtenita:  Basado en la informaci√≥n proporcionada, un Transformer es un modelo de arquitectura que utiliza capas apiladas de auto-atenci√≥n y capas totalmente conectadas puntuales, tanto para el codificador como para el decodificador.  El codificador est√° compuesto por una pila de N=6 capas id√©nticas, cada una con dos subcapas: una de mecanismo de auto-atenci√≥n multi-cabeza y otra, una capa totalmente conectada simple y posicional.  La figura 1 muestra la arquitectura completa del modelo, con el codificador en la mitad izquierda y el decodificador en la mitad derecha.\n",
      "\n",
      "\n",
      "Respuesta esperada:  Se puede descomponer el problema en partes m√°s peque√±as y resolver cada parte por separado.\n",
      "Respuesta obtenita:  Seg√∫n la informaci√≥n proporcionada, Chain of Thought es una t√©cnica que se puede usar para resolver problemas complejos con un LLM.  La informaci√≥n indica que es robusta a diferentes √≥rdenes de ejemplos y a un n√∫mero variable de ellos.  Adem√°s, aunque es particularmente adecuada para problemas matem√°ticos, su naturaleza basada en el lenguaje la hace aplicable a una amplia gama de problemas de razonamiento de sentido com√∫n que involucran el razonamiento sobre interacciones f√≠sicas y humanas bajo la presunci√≥n de conocimiento general.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_other_config(ammount_of_chunks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA**: Al disminuir la cantidad de chunks recuperados, se obtiene una respuesta m√°s general y menos precisa, ya que el modelo obtieen menos contexto de diferentes partes del documento. Sin embargo, la respuesta en este caso es bastante buena, probablemente debido a que el tama√±o de los chunks es lo suficientemente grande para que el modelo pueda responder correctamente, y que el chunk que se obtiene es realmente suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta esperada:  Un Transformer es un tipo de arquitectura de red neuronal que usa un encoder-decoder para modelar relaciones en datos secuenciales.\n",
      "Respuesta obtenita:  El Transformer es una nueva y simple arquitectura de red propuesta como modelo de transducci√≥n de secuencias.  A diferencia de los modelos dominantes basados en redes neuronales recurrentes o convolucionales complejas, el Transformer utiliza √∫nicamente auto-atenci√≥n para calcular representaciones de su entrada y salida, sin usar RNNs o convoluciones alineados con la secuencia.  Es el primer modelo de transducci√≥n que hace esto.  Su arquitectura consta de un codificador y un decodificador, ambos compuestos por una pila de N=6 capas id√©nticas. Cada capa tiene dos subcapas: un mecanismo de auto-atenci√≥n multi-cabeza y una capa totalmente conectada puntual.  El modelo utiliza codificaciones posicionales tanto en el codificador como en el decodificador, y durante el entrenamiento se emplea suavizado de etiquetas con un valor de œµls = 0.1.\n",
      "\n",
      "\n",
      "Respuesta esperada:  Se puede descomponer el problema en partes m√°s peque√±as y resolver cada parte por separado.\n",
      "Respuesta obtenita:  Seg√∫n la informaci√≥n proporcionada, la t√©cnica Chain-of-Thought (pensamiento en cadena) se puede usar para resolver problemas complejos con un LLM.  Esta t√©cnica implica descomponer el problema en pasos intermedios y resolver cada uno antes de dar la respuesta final, imitando un proceso de pensamiento paso a paso.  Adem√°s, es robusta a diferentes √≥rdenes de ejemplos y a un n√∫mero variable de ellos.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_other_config(ammount_of_chunks=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA**: Al aumentar la cantidad de chunks recuperados, se obtiene una respuesta m√°s completa y precisa, ya que el modelo obtiene m√°s contexto de diferentes partes del documento. Esto se cumple en este caso, entregando una respuesta bastante completa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBANDO CAMBIAR TIPO DE BUSQUEDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta esperada:  Un Transformer es un tipo de arquitectura de red neuronal que usa un encoder-decoder para modelar relaciones en datos secuenciales.\n",
      "Respuesta obtenita:  Un Transformer es un modelo de arquitectura que utiliza capas apiladas de auto-atenci√≥n y capas totalmente conectadas puntuales, tanto para el codificador como para el decodificador.  El codificador est√° compuesto por una pila de N=6 capas id√©nticas, cada una con dos subcapas: un mecanismo de auto-atenci√≥n multi-cabeza y una capa de conexi√≥n totalmente conectada posicional.  Se han desarrollado Transformers con diferentes tama√±os; por ejemplo, Vaswani et al. (2017) cre√≥ uno con (L=6, H=1024, A=16) y 100M par√°metros, mientras que el m√°s grande encontrado en la literatura (Al-Rfou et al., 2018) tiene (L=64, H=512, A=2) y 235M par√°metros.  Estos tama√±os se comparan con BERT BASE (110M par√°metros) y BERT LARGE (340M par√°metros).  Un Transformer de 4 capas logr√≥ un F1 de 91.3 en el an√°lisis sint√°ctico de la constituci√≥n inglesa en la secci√≥n 23 de WSJ.\n",
      "\n",
      "\n",
      "Respuesta esperada:  Se puede descomponer el problema en partes m√°s peque√±as y resolver cada parte por separado.\n",
      "Respuesta obtenita:  Seg√∫n la informaci√≥n proporcionada, la t√©cnica Chain of Thought (CoT) se puede usar para resolver problemas complejos con un LLM.  La informaci√≥n indica que CoT es robusta a diferentes √≥rdenes de ejemplos y a un n√∫mero variable de ellos.  Adem√°s, aunque es particularmente adecuada para problemas matem√°ticos, su naturaleza basada en el lenguaje la hace aplicable a una amplia gama de problemas de razonamiento de sentido com√∫n.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_other_config(search_type='mmr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA**: Al cambiar similarity por MMR (Maximal Marginal Relevance), se obtiene una respuesta m√°s completa gracias a la diversidad de los chunks recuperados. Esto dado a que MMR busca chunks que sean diferentes entre s√≠, lo que permite que el modelo tenga m√°s contexto para responder la pregunta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJiPPM0giX8"
   },
   "source": [
    "### **2.2 Agentes (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la secci√≥n anterior, en esta secci√≥n se busca habilitar **Agentes** para obtener informaci√≥n a trav√©s de tools y as√≠ responder la pregunta del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V47l7Mjfrk0N"
   },
   "source": [
    "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas al motor de b√∫squeda **Tavily**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "R6SLKwcWr0AG"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SonB1A-9rtRq"
   },
   "source": [
    "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
    "\n",
    "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lucas\\python-envs\\nb-env\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ehJJpoqsr26-"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(lang='es', top_k_results=1, doc_content_chars_max=100)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvUIMdX6r0ne"
   },
   "source": [
    "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
    "\n",
    "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Aseg√∫rese que su agente responda en espa√±ol. Por √∫ltimo, guarde el agente en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "react_prompt = hub.pull(\"hwchase17/react\") # template de ReAct\n",
    "print(react_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD1_n0wrsDI5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'tavily_search_results_json - A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\\nwikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'tool_names': 'tavily_search_results_json, wikipedia'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001981585DDC0>, default_metadata=()), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[TavilySearchResults(max_results=1, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\lucas\\\\python-envs\\\\nb-env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='es', load_all_available_meta=False, doc_content_chars_max=100))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "tools = [tavily_tool, wiki_tool]\n",
    "\n",
    "agent = create_react_agent(llm, tools, react_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find a list of professors from the Faculty of Physics and Mathematics (FCFM) at the University of Chile.  A Wikipedia search might be a good starting point, but it might not be completely up-to-date.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Faculty of Physics and Mathematics, University of Chile\"\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Universidad de California en Berkeley\n",
      "Summary: La Universidad de California en Berkeley (en id\u001b[0m\u001b[32;1m\u001b[1;3mThought: That was the wrong Wikipedia page. I need to try a different search term.  Let's try searching directly for the faculty's website.  If that doesn't work, I'll try a different approach.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Facultad de Ciencias F√≠sicas y Matem√°ticas, Universidad de Chile\"\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Facultad de Ciencias F√≠sicas y Matem√°ticas de la Universidad de Chile\n",
      "Summary: La Facultad de \u001b[0m\u001b[32;1m\u001b[1;3mThought: The Wikipedia page for the Facultad de Ciencias F√≠sicas y Matem√°ticas (FCFM) of the University of Chile should list faculty members, or at least provide a link to a page that does.  Let's examine the Wikipedia page more closely.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Facultad de Ciencias F√≠sicas y Matem√°ticas, Universidad de Chile\"\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Facultad de Ciencias F√≠sicas y Matem√°ticas de la Universidad de Chile\n",
      "Summary: La Facultad de \u001b[0m\u001b[32;1m\u001b[1;3mThought: The Wikipedia page for the FCFM likely doesn't list all professors.  A web search might be more fruitful in finding a current list of faculty.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"profesores facultad ciencias f√≠sicas y matem√°ticas universidad de chile\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.dii.uchile.cl/~webpgrado2/academicos/listado-de-academicos/', 'content': 'Facultad de Ciencias F√≠sicas y Matem√°ticas; Universidad de Chile; Acad√©micos. Listado de Acad√©micos; Profesores Jornada Parcial; Plan de Estudios. Plan Com√∫n; Malla Curricular; Cursos Electivos; ... Profesor Adjunto. MBA, Universidad de Chile - ESADE, Barcelona . Omar P√©rez Profesor Asistente.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now have a URL that lists professors from the FCFM.  I can't directly access and process the content of the URL, but the observation shows at least one professor's name (Omar P√©rez).  I can't provide a comprehensive list without accessing the linked page.\n",
      "\n",
      "Final Answer:  Based on the provided search results, one professor at the FCFM of the University of Chile is Omar P√©rez.  A more complete list would require accessing the linked website.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided search results, one professor at the FCFM of the University of Chile is Omar P√©rez.  A more complete list would require accessing the linked website.\n"
     ]
    }
   ],
   "source": [
    "def call_agent(input: str):\n",
    "    response = agent_executor.invoke({\"input\": input})\n",
    "    print(response[\"output\"])\n",
    "\n",
    "call_agent(\"Dame el nombre de algunos profesores de la FCFM de la Universidad de Chile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKV0JxK3r-XG"
   },
   "source": [
    "#### **2.2.4 Verificaci√≥n de respuestas (0.3 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente y aseg√∫rese que el agente est√© ocupando correctamente las tools disponibles. ¬øEn qu√© casos el agente deber√≠a ocupar la tool de Tavily? ¬øEn qu√© casos deber√≠a ocupar la tool de Wikipedia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer what Taylor Swift does, I need to find information about her profession.  Wikipedia is a good resource for this.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: The Wikipedia page gives biographical information, but I need to extract her profession.  The summary doesn't explicitly state it, so I'll look further into the page content.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: The Wikipedia page should contain information about her career. I'll look for sections like \"Career\" or \"Profession\".\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to actually *read* the Wikipedia page content this time, not just look at the summary.  I'll look for sections describing her career.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: ¬øA qu√© se dedica Tailor Swift?\n",
      "Thought:To answer what Taylor Swift does, I need to find information about her profession.  Wikipedia is a good resource for this.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: ¬øA qu√© se dedica Tailor Swift?\n",
      "Thought:To answer what Taylor Swift does, I need to find information about her profession.  Wikipedia is a good resource for this.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've repeatedly accessed the Wikipedia page for Taylor Swift without actually extracting the relevant information. I need to access the full page content and find the section describing her career to determine her profession.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've repeatedly accessed the Wikipedia page for Taylor Swift without actually extracting the relevant information. I need to access the full page content and find the section describing her career to determine her profession.  I will simulate accessing the full page content.  The information should be readily available.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've repeatedly failed to extract the information from the simulated Wikipedia page.  I need a different approach.  I'll assume I have access to the full Wikipedia page content and state what I would find.\n",
      "\n",
      "Thought: I now know the final answer.\n",
      "Final Answer: Taylor Swift is a singer-songwriter.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Taylor Swift is a singer-songwriter.\n"
     ]
    }
   ],
   "source": [
    "call_agent(\"¬øA qu√© se dedica Tailor Swift?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find information about the most recent player signing for Real Madrid.  A quick search on Wikipedia might suffice, but a more up-to-date source like a search engine might be better to ensure I have the most recent information.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Real Madrid latest signing\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://en.as.com/soccer/possible-mbappe-signing-with-real-madrid-live-updates-online-as-french-striker-set-to-complete-transfer-n/', 'content': 'Real Madrid have confirmed the signing of France striker Kylian Mbapp√©, who is to join the LaLiga club on a five-year contract. ... Madrid to confirm Mbapp√© deal at \"7:15pm at the very latest\"'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought:The observation shows a news article reporting Kylian Mbapp√©'s signing with Real Madrid.  However, I need to verify this information and check if there have been any signings since then.  I'll use a different search query to be more comprehensive.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Real Madrid recent signings\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.transfermarkt.co.uk/real-madrid/transfers/verein/418/', 'content': 'Transfers: Overview of all signed and sold players of club Real Madrid for the current season. ... Most valuable players in the world Latest transfers Latest rumours Latest market value updates FIFA World Ranking . Be Involved . Mods & Data Scouts Apply as Mod'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought:This observation provides a link to a transfermarkt page listing Real Madrid's transfers.  This is likely to be the most reliable source for a definitive answer.  I will not use Wikipedia as it may not be completely up-to-date on recent transfers.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Real Madrid latest transfer news\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.90min.com/teams/real-madrid/transfer', 'content': 'Latest transfer news for Real Madrid including breaking stories, rumours, transfer targets and opinion. ... Football transfer rumours: Real Madrid plot ‚Ç¨200m Haaland bid; Man Utd eye Vinicius Jr'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought:The provided observations give links to websites, but don't directly state the name of the last signing.  To get a definitive answer, I need to visit those websites.  Since I cannot directly access and browse the internet, I cannot definitively answer the question.  I will attempt to infer the most likely answer based on the provided snippets.  The most recent news snippets mention Kylian Mbapp√©, but lack confirmation.  The Transfermarkt link is promising, but I cannot access it.\n",
      "\n",
      "Thought:I now know the final answer, but it's based on incomplete information.\n",
      "\n",
      "Final Answer: Based on the limited information provided, Kylian Mbapp√© is the most likely candidate for the last signing of Real Madrid, but this cannot be definitively confirmed without accessing the linked websites.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the limited information provided, Kylian Mbapp√© is the most likely candidate for the last signing of Real Madrid, but this cannot be definitively confirmed without accessing the linked websites.\n"
     ]
    }
   ],
   "source": [
    "call_agent(\"¬øQui√©n fue el √∫ltimo fichaje del Real Madrid?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general deber√≠a usar Wikipedia para informaci√≥n especifica que suele estar contenida en wikipedia, mientras que en cualquier otro caso m√°s general deber√≠a usar Tavily. Que tipo de informaci√≥n deber√≠a buscar en wikipedia? Cuando se le pregunta el nombre de una persona, una entidad economica, etc. Es posible que incluso en esos casos se use la de Tavily, pero ese ser√≠a el criterio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZbDTYiogquv"
   },
   "source": [
    "### **2.3 Multi Agente (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
    "\" width=\"450\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsecci√≥n es encapsular las funcionalidades creadas en una soluci√≥n multiagente con un **supervisor**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-iUfH0WvI6m"
   },
   "source": [
    "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
    "\n",
    "Transforme la soluci√≥n RAG de la secci√≥n 2.1 y el agente de la secci√≥n 2.2 a *tools* (una tool por cada uno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def call_rag(question: str) -> str:\n",
    "    \"\"\"Call the RAG model to answer a question\"\"\"\n",
    "    return rag_chain.invoke(question)\n",
    "\n",
    "@tool\n",
    "def call_react(input: str) -> str:\n",
    "    \"\"\"Call the ReAct model to answer a question\"\"\"\n",
    "    return agent_executor.invoke({\"input\": input})[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQYNjT_0vPCg"
   },
   "source": [
    "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
    "\n",
    "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw1cfTtvv1AZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llm\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Eres un agente supervisor de preguntas.\n",
    "    Tu rol es decidir que acci√≥n tomar para poder contestar la pregunta de la mejor manera posible.\n",
    "    - 'llm': Cuando tengas que usar un sistema RAG para extraer informaci√≥n sobre LLMs.\n",
    "    - 'general': Cuando la pregunta sea relacionada a cosas que puedan estar en internet o personas o entidades que conoce wikipedia.\n",
    "    - 'otro': Todo aquella pregunta que no est√© contenida en las categor√≠as anteriores.\n",
    "\n",
    "    No respondas con m√°s de una palabra y no incluyas.\n",
    "\n",
    "    \n",
    "    {question}\n",
    "    \n",
    "\n",
    "    Categor√≠a:\"\"\"\n",
    ")\n",
    "\n",
    "supervisor_chain = (\n",
    "    supervisor_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "supervisor_chain.invoke({\"question\": \"qu√© es BERT?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m supervisor \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Eres un supervisor de respuestas.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Tu rol es verificar que las respuestas entregadas por los modelos sean correctas y cordiales.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    Si la respuesta es correcta, simplemente aprueba la respuesta.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Si la respuesta es incorrecta, puedes corregirla.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Si la respuesta es correcta pero no es cordial, puedes corregirla.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    Recuerda ser amable y cordial en tu respuesta.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    Pregunta: {question}\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    Respuesta cordial:\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28msuper\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     16\u001b[0m     supervisor\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m redirect_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqu√© est√°s pensando?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "redirect_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Eres un asistente experto en el redireccionamiento de preguntas de usuarios.\n",
    "    Vas a recibir una pregunta del usuario, tu √∫nico rol es indicar que no puedes responder su pregunta y redireccionar al usuario\n",
    "    para que te pregunte sobre papers relacionados a LLMs, o sobre cualquier cosa que pueda estar en internet o personas o \n",
    "    entidades que conoce wikipedia.\n",
    "\n",
    "    Recuerda ser amable y cordial en tu respuesta.\n",
    "\n",
    "    Pregunta: {question}\n",
    "    Respuesta cordial:\"\"\"\n",
    ")\n",
    "\n",
    "redirect_chain = (\n",
    "    redirect_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "redirect_chain.invoke({\"question\": \"qu√© est√°s pensando?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(question):\n",
    "  '''\n",
    "  Recibe una pregunta de usuario.\n",
    "  Rutea la pregunta al agente respectivo y responde de manera acorde.\n",
    "  '''\n",
    "\n",
    "  topic = supervisor_chain.invoke({\"question\": question}) # enrutamiento\n",
    "\n",
    "  if \"llm\" in topic:\n",
    "      return call_rag(question)\n",
    "  elif \"general\" in topic:\n",
    "      return call_react(question)\n",
    "  else:\n",
    "      return redirect_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea3zWlvyvY7K"
   },
   "source": [
    "#### **2.3.3 Verificaci√≥n de respuestas (0.25 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. ¬øC√≥mo var√≠an las respuestas bajo este enfoque?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "6_1t0zkgv1qW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un Transformer es un modelo de transducci√≥n que utiliza √∫nicamente auto-atenci√≥n para calcular representaciones de su entrada y salida, sin usar RNNs alineados con la secuencia o convoluciones.  Su arquitectura se compone de un codificador y un decodificador, ambos formados por una pila de N=6 capas id√©nticas. Cada capa tiene dos subcapas: un mecanismo de auto-atenci√≥n multi-cabeza y una capa totalmente conectada puntual.  Tanto el codificador como el decodificador utilizan codificaciones posicionales.  El modelo base utiliza una tasa de abandono (dropout) de Pdrop = 0.1 y durante el entrenamiento se emplea suavizado de etiquetas con un valor de œµls = 0.1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(route_question(\"Qu√© es un Transformer?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seg√∫n la informaci√≥n proporcionada, la t√©cnica Chain of Thought (pensamiento en cadena) se puede usar para resolver problemas complejos con un LLM.  Esta t√©cnica permite descomponer problemas de m√∫ltiples pasos en subproblemas m√°s peque√±os y manejables,  imitando un proceso de pensamiento paso a paso para llegar a la respuesta.  Adem√°s, es robusta a diferentes √≥rdenes de ejemplos y a un n√∫mero variable de ellos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(route_question(\"Seg√∫n Chain of Thought, ¬øqu√© t√©cnica se puede usar para resolver un problema complejo con un LLM?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer what Taylor Swift does, I need to find information about her profession.  Wikipedia is a good resource for this.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: The Wikipedia page gives biographical information, but I need to extract her profession.  The summary doesn't explicitly state it, so I'll look further into the page content.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: The Wikipedia page should contain information about her career. I'll look for sections like \"Career\" or \"Profession\".\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to actually *read* the Wikipedia page content this time, not just look at the summary.  I'll look for sections describing her career.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: ¬øA qu√© se dedica Tailor Swift?\n",
      "Thought:To answer what Taylor Swift does, I need to find information about her profession.  Wikipedia is a good resource for this.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: ¬øA qu√© se dedica Tailor Swift?\n",
      "Thought:To answer what Taylor Swift does, I need to find information about her profession.  Wikipedia is a good resource for this.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've repeatedly accessed the Wikipedia page for Taylor Swift without actually extracting the relevant information. I need to access the full page content and find the section detailing her career to determine her profession.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've repeatedly accessed the Wikipedia page for Taylor Swift without actually extracting the relevant information. I need to access the full page content and find the section detailing her career to determine her profession.  I will simulate accessing the full page content.  The information should be readily available.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: Taylor Swift\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Taylor Swift\n",
      "Summary: Taylor Alison Swift (West Reading, Pensilvania; 13 de diciembre de 1989)\u001b[0m\u001b[32;1m\u001b[1;3mThought: I've repeatedly failed to actually *read* the Wikipedia page.  I need to simulate reading it and extracting the relevant information.  Taylor Swift is a singer-songwriter.\n",
      "\n",
      "Thought: I now know the final answer.\n",
      "Final Answer: Taylor Swift es cantante y compositora.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Taylor Swift es cantante y compositora.\n"
     ]
    }
   ],
   "source": [
    "print(route_question(\"¬øA qu√© se dedica Tailor Swift?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find information about the most recent player signing for Real Madrid.  A quick search on Wikipedia might suffice, but a more up-to-date source like a search engine might be better to ensure I have the most recent information.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Real Madrid latest signing\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://en.as.com/soccer/possible-mbappe-signing-with-real-madrid-live-updates-online-as-french-striker-set-to-complete-transfer-n/', 'content': 'Real Madrid have confirmed the signing of France striker Kylian Mbapp√©, who is to join the LaLiga club on a five-year contract. ... Madrid to confirm Mbapp√© deal at \"7:15pm at the very latest\"'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observation shows a news article reporting Kylian Mbapp√©'s signing with Real Madrid.  However, I need to verify this information and check if there have been any signings since then.  I'll use a different search query to be more comprehensive.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Real Madrid recent signings\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.laliga.com/en-GB/clubs/real-madrid/transfers', 'content': \"Real Madrid REAL MADRID CLUB DE F√öTBOL LATEST SIGNINGS OF THE REAL MADRID Who are the last-minute signings of Real Madrid? Don't miss out on any Real Madrid transfers on the LALIGA transfer market! Find out about the latest signings of Real Madrid at LALIGA.com, the only website that has official information on the signings of LALIGA EA SPORTS and LALIGA HYPERMOTION. Follow all the information about the latest Real Madrid signings that have joined your club in this transfer market. The last-minute signings of Real Madrid that will defend your club's colors next season 2021/22 in LALIGA. Get to know the transfer market live and stay updated with the latest official incorporations of LALIGA EA SPORTS and LALIGA HYPERMOTION!\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The second search result points to a LaLiga website, which should have official information.  However, the content snippet is vague. I need to directly access the website to get the most accurate and up-to-date information.  Since I can't directly access and process websites, I'll have to rely on the information I already have, acknowledging its limitations.  The first search result strongly suggests Kylian Mbapp√© as the latest signing, but it's crucial to remember that this is based on a news article and might not be completely confirmed.\n",
      "\n",
      "Thought: I now know the final answer.\n",
      "\n",
      "Final Answer: Based on available information, Kylian Mbapp√© is reported to be the latest signing for Real Madrid, but this information should be considered preliminary until officially confirmed by Real Madrid or a reliable, official source.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on available information, Kylian Mbapp√© is reported to be the latest signing for Real Madrid, but this information should be considered preliminary until officially confirmed by Real Madrid or a reliable, official source.\n"
     ]
    }
   ],
   "source": [
    "print(route_question(\"Qui√©n fue el √∫ltimo fichaje del Real Madrid?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb8bdAmYvgwn"
   },
   "source": [
    "#### **2.3.4 An√°lisis (0.25 puntos)**\n",
    "\n",
    "¬øQu√© diferencias tiene este enfoque con la soluci√≥n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAUlJxqoLK5r"
   },
   "source": [
    "`escriba su respuesta ac√°`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JWVSuWiZ8Mj"
   },
   "source": [
    "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
    "\n",
    "- Pregunta 1: \"Hola! mi nombre es Sebasti√°n\"\n",
    "  - Respuesta esperada: \"Hola Sebasti√°n! ...\"\n",
    "- Pregunta 2: \"Cual es mi nombre?\"\n",
    "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
    "  - **Respuesta esperada: \"Tu nombre es Sebasti√°n\"**\n",
    "\n",
    "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluci√≥n entregada en el punto 2.3.\n",
    "\n",
    "**Nota: El Bonus es v√°lido <u>s√≥lo para la secci√≥n 2 de Large Language Models.</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6Y7tIPJLPfB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFc3jBT5g0kT"
   },
   "source": [
    "### **2.5 Despliegue (0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a trav√©s de `gradio`, una librer√≠a especializada en el levantamiento r√°pido de demos basadas en ML.\n",
    "\n",
    "Primero instalamos la librer√≠a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "T8TsvnCPbkIA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-chroma 0.1.1 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.19 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJBztEUovKsF"
   },
   "source": [
    "Luego s√≥lo deben ejecutar el siguiente c√≥digo e interactuar con la interfaz a trav√©s del notebook o del link generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Z3KedQSvg1-n"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magent_response\u001b[39m(message, history):\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gradio\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_simple_templates\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gradio\\_simple_templates\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpledropdown\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDropdown\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpleimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImage\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpletextbox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleTextbox\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gradio\\_simple_templates\\simpledropdown.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Sequence\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Component, FormComponent\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Events\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gradio\\components\\__init__.py:40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model3D\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultimodal_textbox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultimodalTextbox\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnative_plot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BarPlot, LinePlot, NativePlot, ScatterPlot\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Number\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparamviewer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParamViewer\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\gradio\\components\\native_plot.py:12\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Sequence, Set\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m      8\u001b[0m     Any,\n\u001b[0;32m      9\u001b[0m     Literal,\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocumentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m document\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Component\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\pandas\\__init__.py:59\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     ArrowDtype,\n\u001b[0;32m     62\u001b[0m     Int8Dtype,\n\u001b[0;32m     63\u001b[0m     Int16Dtype,\n\u001b[0;32m     64\u001b[0m     Int32Dtype,\n\u001b[0;32m     65\u001b[0m     Int64Dtype,\n\u001b[0;32m     66\u001b[0m     UInt8Dtype,\n\u001b[0;32m     67\u001b[0m     UInt16Dtype,\n\u001b[0;32m     68\u001b[0m     UInt32Dtype,\n\u001b[0;32m     69\u001b[0m     UInt64Dtype,\n\u001b[0;32m     70\u001b[0m     Float32Dtype,\n\u001b[0;32m     71\u001b[0m     Float64Dtype,\n\u001b[0;32m     72\u001b[0m     CategoricalDtype,\n\u001b[0;32m     73\u001b[0m     PeriodDtype,\n\u001b[0;32m     74\u001b[0m     IntervalDtype,\n\u001b[0;32m     75\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     76\u001b[0m     StringDtype,\n\u001b[0;32m     77\u001b[0m     BooleanDtype,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     NA,\n\u001b[0;32m     80\u001b[0m     isna,\n\u001b[0;32m     81\u001b[0m     isnull,\n\u001b[0;32m     82\u001b[0m     notna,\n\u001b[0;32m     83\u001b[0m     notnull,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     Index,\n\u001b[0;32m     86\u001b[0m     CategoricalIndex,\n\u001b[0;32m     87\u001b[0m     RangeIndex,\n\u001b[0;32m     88\u001b[0m     MultiIndex,\n\u001b[0;32m     89\u001b[0m     IntervalIndex,\n\u001b[0;32m     90\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     91\u001b[0m     DatetimeIndex,\n\u001b[0;32m     92\u001b[0m     PeriodIndex,\n\u001b[0;32m     93\u001b[0m     IndexSlice,\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     NaT,\n\u001b[0;32m     96\u001b[0m     Period,\n\u001b[0;32m     97\u001b[0m     period_range,\n\u001b[0;32m     98\u001b[0m     Timedelta,\n\u001b[0;32m     99\u001b[0m     timedelta_range,\n\u001b[0;32m    100\u001b[0m     Timestamp,\n\u001b[0;32m    101\u001b[0m     date_range,\n\u001b[0;32m    102\u001b[0m     bdate_range,\n\u001b[0;32m    103\u001b[0m     Interval,\n\u001b[0;32m    104\u001b[0m     interval_range,\n\u001b[0;32m    105\u001b[0m     DateOffset,\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     to_numeric,\n\u001b[0;32m    108\u001b[0m     to_datetime,\n\u001b[0;32m    109\u001b[0m     to_timedelta,\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     Flags,\n\u001b[0;32m    112\u001b[0m     Grouper,\n\u001b[0;32m    113\u001b[0m     factorize,\n\u001b[0;32m    114\u001b[0m     unique,\n\u001b[0;32m    115\u001b[0m     value_counts,\n\u001b[0;32m    116\u001b[0m     NamedAgg,\n\u001b[0;32m    117\u001b[0m     array,\n\u001b[0;32m    118\u001b[0m     Categorical,\n\u001b[0;32m    119\u001b[0m     set_eng_float_format,\n\u001b[0;32m    120\u001b[0m     Series,\n\u001b[0;32m    121\u001b[0m     DataFrame,\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmissing.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\pandas\\_libs\\tslibs\\__init__.py:39\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalize_pydatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_supported_reso\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m ]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes  \u001b[38;5;66;03m# pylint: disable=import-self\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m localize_pydatetime\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m     Resolution,\n\u001b[0;32m     42\u001b[0m     get_supported_reso,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     periods_per_second,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnattype\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     49\u001b[0m     NaT,\n\u001b[0;32m     50\u001b[0m     NaTType,\n\u001b[0;32m     51\u001b[0m     iNaT,\n\u001b[0;32m     52\u001b[0m     nat_strings,\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32mconversion.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32moffsets.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.offsets\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtimestamps.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.timestamps\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtimedeltas.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.timedeltas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtimezones.pyx:49\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.timezones\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\dateutil\\tz\\tz.py:1557\u001b[0m, in \u001b[0;36m__get_gettz.<locals>.GettzFunc.__call__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1554\u001b[0m rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__instances\u001b[38;5;241m.\u001b[39mget(name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1557\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnocache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rv, tzlocal_classes)\n\u001b[0;32m   1560\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m rv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1565\u001b[0m         \u001b[38;5;66;03m# We also cannot store weak references to None, so we\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m         \u001b[38;5;66;03m# will also not store that.\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__instances[name] \u001b[38;5;241m=\u001b[39m rv\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\dateutil\\tz\\tz.py:1648\u001b[0m, in \u001b[0;36m__get_gettz.<locals>.GettzFunc.nocache\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tzwin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1648\u001b[0m         tz \u001b[38;5;241m=\u001b[39m \u001b[43mtzwin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mWindowsError\u001b[39;00m, \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m):\n\u001b[0;32m   1650\u001b[0m         \u001b[38;5;66;03m# UnicodeEncodeError is for Python 2.7 compat\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m         tz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\dateutil\\tz\\win.py:221\u001b[0m, in \u001b[0;36mtzwin.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    219\u001b[0m     tzkeyname \u001b[38;5;241m=\u001b[39m text_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{kn}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(kn\u001b[38;5;241m=\u001b[39mTZKEYNAME, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m winreg\u001b[38;5;241m.\u001b[39mOpenKey(handle, tzkeyname) \u001b[38;5;28;01mas\u001b[39;00m tzkey:\n\u001b[1;32m--> 221\u001b[0m         keydict \u001b[38;5;241m=\u001b[39m \u001b[43mvaluestodict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtzkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_std_abbr \u001b[38;5;241m=\u001b[39m keydict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dst_abbr \u001b[38;5;241m=\u001b[39m keydict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDlt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lucas\\python-envs\\nb-env\\Lib\\site-packages\\dateutil\\tz\\win.py:354\u001b[0m, in \u001b[0;36mvaluestodict\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    351\u001b[0m tz_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(size):\n\u001b[1;32m--> 354\u001b[0m     key_name, value, dtype \u001b[38;5;241m=\u001b[39m \u001b[43mwinreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEnumValue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m winreg\u001b[38;5;241m.\u001b[39mREG_DWORD \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m winreg\u001b[38;5;241m.\u001b[39mREG_DWORD_LITTLE_ENDIAN:\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;66;03m# If it's a DWORD (32-bit integer), it's stored as unsigned - convert\u001b[39;00m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;66;03m# that to a proper signed integer\u001b[39;00m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m31\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def agent_response(message, history):\n",
    "  '''\n",
    "  Funci√≥n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
    "  '''\n",
    "  # get chatbot response\n",
    "  response = ... # rellenar con la respuesta de su chat\n",
    "\n",
    "  # assert\n",
    "  assert type(response) == str, \"output de route_question debe ser string\"\n",
    "\n",
    "  # \"streaming\" response\n",
    "  for i in range(len(response)):\n",
    "    time.sleep(0.015)\n",
    "    yield response[: i+1]\n",
    "\n",
    "gr.ChatInterface(\n",
    "    agent_response,\n",
    "    type=\"messages\",\n",
    "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
    "    description=\"Hola! Soy un chatbot muy √∫til :)\", # tambi√©n la descripci√≥n\n",
    "    theme=\"soft\",\n",
    "    ).launch(\n",
    "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
    "        debug = False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
